{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7JoXbPoXy_F"
      },
      "outputs": [],
      "source": [
        "%pip install onedrivedownloader matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsYE8NBYW0nk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gzip\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from onedrivedownloader import download\n",
        "\n",
        "download('https://unimore365-my.sharepoint.com/:u:/g/personal/215580_unimore_it/EXhnxAKIfcdIqSRJoFc_C6EBCT6S0CNLOYFW3ShqivC46w?e=Ii4NOp',\n",
        "                                                      filename='./mnist/mnist_mnist.zip',\n",
        "                                                      unzip=True)\n",
        "\n",
        "def load_mnist_digits():\n",
        "    \"\"\"\n",
        "    Loads mnist (original, with digits).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple:\n",
        "        x_train with shape(n_train_samples, h, w)\n",
        "        y_train with shape(n_train_samples,)\n",
        "        x_test with shape(n_test_samples, h, w)\n",
        "        y_test with shape(n_test_samples,)\n",
        "    \"\"\"\n",
        "\n",
        "    x_train = np.load('mnist/x_train.npy')\n",
        "    y_train = np.load('mnist/y_train.npy')\n",
        "\n",
        "    x_test = np.load('mnist/x_test.npy')\n",
        "    y_test = np.load('mnist/y_test.npy')\n",
        "\n",
        "    label_dict = {i: str(i) for i in range(0, 10)}\n",
        "\n",
        "    return x_train, y_train, x_test, y_test, label_dict\n",
        "\n",
        "\n",
        "def load_mnist(threshold=0.5):\n",
        "    \"\"\"\n",
        "    Loads MNIST data (either digits or fashion) and returns it binarized.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    threshold: float\n",
        "        a threshold in [0, 1] to binarize w.r.t.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple:\n",
        "        x_train with shape(n_train_samples, h, w)\n",
        "        y_train with shape(n_train_samples,)\n",
        "        x_test with shape(n_test_samples, h, w)\n",
        "        y_test with shape(n_test_samples,)\n",
        "    \"\"\"\n",
        "\n",
        "    x_train, y_train, x_test, y_test, label_dict = load_mnist_digits()\n",
        "\n",
        "    x_train = np.float32(x_train) / 255.\n",
        "    x_train[x_train >= threshold] = 1\n",
        "    x_train[x_train < threshold] = 0\n",
        "\n",
        "    x_test = np.float32(x_test) / 255.\n",
        "    x_test[x_test >= threshold] = 1\n",
        "    x_test[x_test < threshold] = 0\n",
        "\n",
        "    return x_train, y_train, x_test, y_test, label_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ua32NN0TYHga"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Class that models a Naive Bayes Classifier\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class NaiveBayesClassifier:\n",
        "    \"\"\"\n",
        "    Naive Bayes Classifier.\n",
        "    Training:\n",
        "    For each class, a naive likelihood model is estimated for P(X/Y),\n",
        "    and the prior probability P(Y) is computed.\n",
        "    Inference:\n",
        "    performed according with the Bayes rule:\n",
        "    P = argmax_Y (P(X/Y) * P(Y))\n",
        "    or\n",
        "    P = argmax_Y (log(P(X/Y)) + log(P(Y)))\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Class constructor\n",
        "        \"\"\"\n",
        "\n",
        "        self._classes = None\n",
        "        self._n_classes = 0\n",
        "\n",
        "        self._eps = np.finfo(np.float32).eps\n",
        "\n",
        "        # array of classes prior probabilities\n",
        "        self._class_priors = []\n",
        "\n",
        "        # array of probabilities of a pixel being active (for each class)\n",
        "        self._pixel_probs_given_class = []\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        \"\"\"\n",
        "        Computes, for each class, a naive likelihood model (self._pixel_probs_given_class),\n",
        "        and a prior probability (self.class_priors).\n",
        "        Both quantities are estimated from examples X and Y.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: np.array\n",
        "            input MNIST digits. Has shape (n_train_samples, h, w)\n",
        "        Y: np.array\n",
        "            labels for MNIST digits. Has shape (n_train_samples,)\n",
        "        \"\"\"\n",
        "\n",
        "        # trovare i parametri del modello per ogni classe per la gaussiana\n",
        "        # trovare la probabilitÃ  a priori per ogni classe (numero di esempi di quella classe / numero totale di esempi)\n",
        "        # trovare la varianza per ogni pixel per ogni classe _pixel_means_given_class\n",
        "        # _pixel_std_given_class = np.sqrt(_pixel_vars_given_class)\n",
        "\n",
        "        # LDA\n",
        "        # trovare la varianza per ogni pixel per ogni classe _pixel_vars_given_class\n",
        "        # global_std_dev = np.stack(_pixel_std_given_class).mean(axis=0)\n",
        "        # _pixel_vars_given_class = np.stack(_pixel_vars_given_class)\n",
        "\n",
        "        yclass, counts = np.unique(Y, return_counts=True)\n",
        "\n",
        "        self._classes = yclass\n",
        "        self._n_classes = len(yclass)\n",
        "        self._class_priors = counts / X.shape[0]\n",
        "\n",
        "        for i in range(self._n_classes):\n",
        "            pixel_prob_given_i = np.mean(X[Y == i], axis=0)\n",
        "            # pixel_prob_given_i = np.std(X[Y == i], axis=0)\n",
        "            self._pixel_probs_given_class.append(pixel_prob_given_i)\n",
        "\n",
        "    def predict(self, X, return_pred=False):\n",
        "        \"\"\"\n",
        "        Performs inference on test data.\n",
        "        Inference is performed according with the Bayes rule:\n",
        "        P = argmax_Y (log(P(X/Y)) + log(P(Y)) - log(P(X)))\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: np.array\n",
        "            MNIST test images. Has shape (n_test_samples, h, w).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        prediction: np.array\n",
        "            model predictions over X. Has shape (n_test_samples,)\n",
        "        \"\"\"\n",
        "\n",
        "        n_test_images = X.shape[0]\n",
        "        num_pixels_per_image = X.shape[1]\n",
        "\n",
        "        results = np.zeros((n_test_images, self._n_classes))\n",
        "\n",
        "        mask_one = X == 1.0\n",
        "        mask_zero = X == 0.0\n",
        "\n",
        "        for i in range(self._n_classes):\n",
        "            model_of_i = self._pixel_probs_given_class[i]\n",
        "            model_of_i = model_of_i.reshape((1, num_pixels_per_image))\n",
        "\n",
        "            pixel_likelihoods = mask_one * model_of_i + mask_zero * (1.0 - model_of_i)\n",
        "            pixel_likelihoods_log = np.log(pixel_likelihoods + self._eps)\n",
        "            class_likelihoods_log = np.sum(pixel_likelihoods_log, axis=1)\n",
        "\n",
        "            class_prior_log = np.log(self._class_priors[i])\n",
        "\n",
        "            final_log_score = class_likelihoods_log + class_prior_log\n",
        "            results[:, i] = final_log_score\n",
        "\n",
        "        if not return_pred:\n",
        "            return np.argmax(results, axis=1)\n",
        "        return np.argmax(results, axis=1), results\n",
        "\n",
        "    @staticmethod\n",
        "    def _estimate_pixel_probabilities(images):\n",
        "        \"\"\"\n",
        "        [OPTIONAL!]\n",
        "        Estimates pixel probabilities from data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        images: np.array\n",
        "            images to estimate pixel probabilities from. Has shape (n_images, h, w)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pix_probs: np.array\n",
        "            probabilities for each pixel of being 1, estimated from images.\n",
        "            Has shape (h, w)\n",
        "        \"\"\"\n",
        "        return None\n",
        "\n",
        "    def get_log_likelihood_under_model(self, images, model):\n",
        "        \"\"\"\n",
        "        [OPTIONAL!]\n",
        "        Returns the likelihood of many images under a certain model.\n",
        "        Naive:\n",
        "        the likelihood of the image is the product of the likelihood of each pixel.\n",
        "        or\n",
        "        the log-likelihood of the image is the sum of the log-likelihood of each pixel.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        images: np.array\n",
        "            input images. Having shape (n_images, h, w).\n",
        "        model: np.array\n",
        "            a model of pixel probabilities, having shape (h, w)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        lkl: np.array\n",
        "            the likelihood of each pixel under the model, having shape (h, w).\n",
        "        \"\"\"\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa15Lpq2as0A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_train, y_train, x_test, y_test, label_dict = load_mnist(threshold=0.5)\n",
        "\n",
        "print(f\"Training set -> number of examples: {len(x_train)}\")\n",
        "print(f\"Test set -> number of examples: {len(x_test)}\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"X -> shape: {x_train.shape}\")\n",
        "print(f\"X -> dtype: {x_train.dtype}\")\n",
        "print(f\"X -> min: {x_train.min()}\")\n",
        "print(f\"X -> max: {x_train.max()}\")\n",
        "print(f\"X -> values: {np.unique(x_train)}\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"Classes: {(np.unique(y_train))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fu6xDJRbyff"
      },
      "outputs": [],
      "source": [
        "num_row, num_col = 1, 10\n",
        "len_tr = len(x_train)\n",
        "f, subplots = plt.subplots(num_row, num_col, sharex='col', sharey='row')\n",
        "\n",
        "for cls in np.unique(y_train):\n",
        "    idx = np.arange(len_tr)[y_train == cls]\n",
        "    idx = np.random.choice(idx)\n",
        "    X_img = x_train[idx]\n",
        "    subplots[cls].imshow(X_img, cmap='gray',\n",
        "                       interpolation='nearest', aspect='auto')\n",
        "    subplots[cls].set_title(f'Digit {cls}', fontweight=\"bold\")\n",
        "    subplots[cls].grid(visible=False)\n",
        "    subplots[cls].axis('off')\n",
        "\n",
        "f.set_size_inches(22.5, 4.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0veJlp2fNEI"
      },
      "source": [
        "**Step 1: training the Naive Bayes classifier on the training set.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igAkkWhAfFEX"
      },
      "outputs": [],
      "source": [
        "# get the model\n",
        "nbc = NaiveBayesClassifier()\n",
        "\n",
        "# train\n",
        "nbc.fit(x_train, y_train)\n",
        "\n",
        "# media, deviazione standard e varianza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1aGqvp4fpDB"
      },
      "source": [
        "**Step 2: evaluating the performance of the classifier on a set of unseen data (test set).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVcK2ezWfIkX"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(targets, predictions, classes,\n",
        "                          normalize=True,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    n_classes, = np.unique(targets).shape\n",
        "\n",
        "    cm = np.zeros(shape=(n_classes, n_classes), dtype=np.float32)\n",
        "    for t, p in zip(targets, predictions):\n",
        "        cm[int(t), int(p)] += 1\n",
        "\n",
        "    if normalize:\n",
        "        cm /= cm.sum(axis=1)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# test\n",
        "predictions = nbc.predict(x_test.reshape((len(x_test), -1)))\n",
        "\n",
        "# evaluate performances\n",
        "accuracy = np.sum(np.uint8(predictions == y_test)) / len(y_test)\n",
        "print('Accuracy: {}'.format(accuracy))\n",
        "\n",
        "# show confusion matrix\n",
        "plot_confusion_matrix(targets=y_test,\n",
        "                      predictions=predictions,\n",
        "                      classes=[label_dict[l] for l in label_dict])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXYFDINAYLpi"
      },
      "outputs": [],
      "source": [
        "idx = np.random.randint(0, x_test.shape[0])\n",
        "\n",
        "x = x_test[idx]\n",
        "p = predictions[idx]\n",
        "y = y_test[idx]\n",
        "\n",
        "plt.imshow(x, cmap='gray')\n",
        "plt.title('Target: {}, Prediction: {}'.format(label_dict[int(y)], label_dict[int(p)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
